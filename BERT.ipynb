{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objects as go\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim = pd.read_csv('Climate_twitter.csv')\n",
    "bt = pd.read_csv('twitter_sentiment_data.csv')\n",
    "json = pd.read_json('train.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>likes</th>\n",
       "      <th>text</th>\n",
       "      <th>twitter_name</th>\n",
       "      <th>location</th>\n",
       "      <th>verified</th>\n",
       "      <th>followers</th>\n",
       "      <th>friends</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2184934963</td>\n",
       "      <td>2020-12-22 23:22:20</td>\n",
       "      <td>71</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>GO GREEN</td>\n",
       "      <td>91</td>\n",
       "      <td>The death of summer Arctic ice our Earth coole...</td>\n",
       "      <td>ECOWARRIORSS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>23415</td>\n",
       "      <td>20439</td>\n",
       "      <td>-0.054365</td>\n",
       "      <td>0.426984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>508658626</td>\n",
       "      <td>2020-12-10 14:30:00</td>\n",
       "      <td>14</td>\n",
       "      <td>Twitter for Advertisers</td>\n",
       "      <td>Elsevier Energy</td>\n",
       "      <td>98</td>\n",
       "      <td>Elsevier and the EditorsinChief are pleased to...</td>\n",
       "      <td>ElsevierEnergy</td>\n",
       "      <td>Oxford, England</td>\n",
       "      <td>False</td>\n",
       "      <td>6615</td>\n",
       "      <td>508</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2607105006</td>\n",
       "      <td>2020-12-22 21:28:52</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Arwyn Thomas</td>\n",
       "      <td>1</td>\n",
       "      <td>From better climate change education to improv...</td>\n",
       "      <td>siwarr5</td>\n",
       "      <td>Carmarthen</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>133</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.345238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19609660</td>\n",
       "      <td>2020-12-22 21:24:10</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Tom Gillispie, EDITOR/WRITER</td>\n",
       "      <td>0</td>\n",
       "      <td>climate change Links to FIXING CLIMATE CHANGE ...</td>\n",
       "      <td>EDITORatWORK</td>\n",
       "      <td>Rural Hall, North Carolina, USA</td>\n",
       "      <td>False</td>\n",
       "      <td>4191</td>\n",
       "      <td>3708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19609660</td>\n",
       "      <td>2020-12-21 22:52:09</td>\n",
       "      <td>1</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Tom Gillispie, EDITOR/WRITER</td>\n",
       "      <td>1</td>\n",
       "      <td>climate change The 11TH HOUR FOR THE EARTH cli...</td>\n",
       "      <td>EDITORatWORK</td>\n",
       "      <td>Rural Hall, North Carolina, USA</td>\n",
       "      <td>False</td>\n",
       "      <td>4191</td>\n",
       "      <td>3708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                 date  retweets                   source  \\\n",
       "0  2184934963  2020-12-22 23:22:20        71          Twitter Web App   \n",
       "1   508658626  2020-12-10 14:30:00        14  Twitter for Advertisers   \n",
       "2  2607105006  2020-12-22 21:28:52         0          Twitter Web App   \n",
       "3    19609660  2020-12-22 21:24:10         0          Twitter Web App   \n",
       "4    19609660  2020-12-21 22:52:09         1          Twitter Web App   \n",
       "\n",
       "                         author  likes  \\\n",
       "0                      GO GREEN     91   \n",
       "1               Elsevier Energy     98   \n",
       "2                  Arwyn Thomas      1   \n",
       "3  Tom Gillispie, EDITOR/WRITER      0   \n",
       "4  Tom Gillispie, EDITOR/WRITER      1   \n",
       "\n",
       "                                                text    twitter_name  \\\n",
       "0  The death of summer Arctic ice our Earth coole...    ECOWARRIORSS   \n",
       "1  Elsevier and the EditorsinChief are pleased to...  ElsevierEnergy   \n",
       "2  From better climate change education to improv...         siwarr5   \n",
       "3  climate change Links to FIXING CLIMATE CHANGE ...    EDITORatWORK   \n",
       "4  climate change The 11TH HOUR FOR THE EARTH cli...    EDITORatWORK   \n",
       "\n",
       "                          location  verified  followers  friends  polarity  \\\n",
       "0                              NaN     False      23415    20439 -0.054365   \n",
       "1                  Oxford, England     False       6615      508  0.387500   \n",
       "2                       Carmarthen     False         22      133  0.261905   \n",
       "3  Rural Hall, North Carolina, USA     False       4191     3708  0.000000   \n",
       "4  Rural Hall, North Carolina, USA     False       4191     3708  0.000000   \n",
       "\n",
       "   subjectivity    label  \n",
       "0      0.426984        0  \n",
       "1      0.633333        1  \n",
       "2      0.345238        1  \n",
       "3      0.000000  neutral  \n",
       "4      0.000000  neutral  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding label based on polarity score\n",
    "conditions = [\n",
    "    (clim['polarity'] < 0),\n",
    "    (clim['polarity'] > 0),\n",
    "    (clim['polarity'] == 0)]\n",
    "\n",
    "values = [0,1, 'neutral']\n",
    "\n",
    "clim['label'] = np.select(conditions, values)\n",
    "\n",
    "clim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping neutral entries\n",
    "clim = clim.drop(clim[clim['label'] == 'neutral'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping all columns except text and label\n",
    "clim = clim.drop(columns = ['id','date','source','author','twitter_name','location','verified','retweets','likes','followers','friends','polarity','subjectivity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 270 entries, 0 to 395\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    270 non-null    object\n",
      " 1   label   270 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 6.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 270 entries, 0 to 395\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    270 non-null    string\n",
      " 1   label   270 non-null    int64 \n",
      "dtypes: int64(1), string(1)\n",
      "memory usage: 6.3 KB\n"
     ]
    }
   ],
   "source": [
    "clim.info()\n",
    "clim['text'] = clim['text'].astype('string')\n",
    "clim['label'] = clim['label'].astype('int64')\n",
    "clim.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.head()\n",
    "bt = bt.drop(columns=['tweetid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.rename(columns={'sentiment': \"label\", 'message':'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43943 entries, 0 to 43942\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   43943 non-null  int64 \n",
      " 1   text    43943 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 686.7+ KB\n"
     ]
    }
   ],
   "source": [
    "bt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       " 1    22962\n",
       " 2     9276\n",
       " 0     7715\n",
       "-1     3990\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt['label'].value_counts() # imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = bt.drop(bt[bt['label'] ==  2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = bt.drop(bt[bt['label'] == 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.dropna(subset=['label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (bt['label'] == -1),\n",
    "    (bt['label'] == 1)]\n",
    "\n",
    "values = [0,1]\n",
    "\n",
    "bt['sent'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt['label'] = bt['sent']\n",
    "bt=bt.drop(columns=['sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 26952 entries, 0 to 43942\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   26952 non-null  int64 \n",
      " 1   text    26952 non-null  string\n",
      "dtypes: int64(1), string(1)\n",
      "memory usage: 631.7 KB\n"
     ]
    }
   ],
   "source": [
    "bt['text'] = bt['text'].astype(\"string\")\n",
    "bt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    22962\n",
       "0     3990\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2117 entries, 0 to 2116\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    2117 non-null   object\n",
      " 1   label   2117 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 33.2+ KB\n"
     ]
    }
   ],
   "source": [
    "json.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    1585\n",
       "1     532\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 29339 entries, 0 to 2116\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    29339 non-null  object\n",
      " 1   label   29339 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 687.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_list = [clim, bt, json]\n",
    "df = pd.concat(df_list)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    23684\n",
       "0     5655\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Preprocessing: Filteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/tessanderson/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download the lexicon\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "# Import the lexicon\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create an instance of SentimentIntensityAnalyzer\n",
    "sent_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tessanderson/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')  # Download the punkt tokenizer if not already downloaded\n",
    "\n",
    "df['tokens'] = df['text'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"sustainability\", \"environmental\", \"conservation\", \"recycling\", \"sustainable\",\n",
    "                         \"responsibility\", \"green\", \"eco-friendly\", \"renewable\", \"carbon\", \"climate\", \"ecosystem\",\n",
    "                         \"planet\", \"biodiversity\", \"energy\", \"water\", \"pollution\", \"reduction\", \"renewability\",\n",
    "                         \"ecological\", \"renewable\", \"greenhouse\", \"clean\", \"solar\", \"wind\", \"earth\", \"sustainable\",\n",
    "                         \"planet\", \"ecology\", \"ocean\", \"forest\", \"organic\", \"earth-friendly\", \"bio\", \"ethics\",\n",
    "                         \"conservationist\", \"sustain\", \"renew\", \"ethical\", \"greenery\", \"saver\", \"sustainable\",\n",
    "                         \"conservator\", \"recycler\", \"biodegradable\", \"natural\", \"greenery\", \"environment\",\n",
    "                         \"saver\", \"earth-saving\", \"sustainability\", \"green-living\", \"clean\", \"responsible\",\n",
    "                         \"preservation\", \"regeneration\", \"ecosystem\", \"safeguarding\"]\n",
    "filtered_df = df[df['tokens'].apply(lambda tokens: any(keyword in tokens for keyword in keywords))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    19287\n",
       "0     2412\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When we are using an imbalanced dataset, we can oversample the minority class using replacement. Thsi tehnique is called oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 38574 entries, 20004 to 2115\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    38574 non-null  string\n",
      " 1   label   38574 non-null  int64 \n",
      " 2   tokens  38574 non-null  object\n",
      "dtypes: int64(1), object(1), string(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    19287\n",
       "1    19287\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "df1 = filtered_df.loc[filtered_df['label'] == 0]\n",
    "df2 = filtered_df.loc[filtered_df['label'] == 1]\n",
    "df1_sampled=resample(df1, replace=True,\n",
    "                     n_samples= 19287,\n",
    "                     random_state=42)\n",
    "# reproducible results\n",
    "filtered_df= pd.concat([df1_sampled, df2])\n",
    "filtered_df.info()\n",
    "filtered_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data: train, test, and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = filtered_df.text.values\n",
    "y = filtered_df.label.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec=CountVectorizer()\n",
    "vec.fit(X_train)\n",
    "X_train=vec.transform(X_train)\n",
    "X_test=vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 128\n",
    "#tokenize and encode the sentences\n",
    "X_train_encoded = tokenizer.batch_encode_plus(filtered_df['text'].tolist(),\n",
    "                                              padding = True,\n",
    "                                              truncation = True,\n",
    "                                              max_length = max_len,\n",
    "                                              return_tensors = 'tf')\n",
    "\n",
    "X_val_encoded = tokenizer.batch_encode_plus(X_val.tolist(),\n",
    "                                            padding = True,\n",
    "                                            truncation = True,\n",
    "                                            max_length = max_len,\n",
    "                                            return_tensors = 'tf')\n",
    "\n",
    "X_test_encoded = tokenizer.batch_encode_plus(X_test.tolist(),\n",
    "                                             padding = True,\n",
    "                                             truncation = True,\n",
    "                                             max_length = max_len,\n",
    "                                             return_tensors = 'tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "print(\"Training comments -->\", filtered_df.text[k])\n",
    "print(\"\\nInput IDs -->\\n\", X_train_encoded['input_ids'][k])\n",
    "print(\"\\nDecoded IDs -->\\n\", tokenizer.decode(X_train_encoded['input_ids'][k]))\n",
    "print(\"\\nAttention Mask -->\\n\", X_train_encoded['attention_mask'][k])\n",
    "print(\"\\nLabels -->\", filtered_df.label[k])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesiswork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
