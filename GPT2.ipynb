{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "411c7833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\sayan\\anaconda3\\lib\\site-packages (4.37.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sayan\\anaconda3\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\sayan\\anaconda3\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: requests in c:\\users\\sayan\\anaconda3\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\sayan\\anaconda3\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sayan\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\sayan\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sayan\\anaconda3\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sayan\\anaconda3\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sayan\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sayan\\anaconda3\\lib\\site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sayan\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sayan\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\sayan\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sayan\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sayan\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sayan\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sayan\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sayan\\anaconda3\\lib\\site-packages (from requests->transformers) (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd45d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import GPT2Tokenizer, TFGPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa1ca5d1",
   "metadata": {
    "id": "xEmEfk8IqVOa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60e7d11",
   "metadata": {
    "id": "bL2AVkFbsV8v"
   },
   "source": [
    "We'll read the tweet file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67b77d3a",
   "metadata": {
    "id": "GluhmiLpqqHf"
   },
   "outputs": [],
   "source": [
    "clim = pd.read_csv('Climate_twitter.csv')\n",
    "bt = pd.read_csv('twitter_sentiment_data.csv')\n",
    "json = pd.read_json('train.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f6959eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>likes</th>\n",
       "      <th>text</th>\n",
       "      <th>twitter_name</th>\n",
       "      <th>location</th>\n",
       "      <th>verified</th>\n",
       "      <th>followers</th>\n",
       "      <th>friends</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2184934963</td>\n",
       "      <td>2020-12-22 23:22:20</td>\n",
       "      <td>71</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>GO GREEN</td>\n",
       "      <td>91</td>\n",
       "      <td>The death of summer Arctic ice our Earth coole...</td>\n",
       "      <td>ECOWARRIORSS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>23415</td>\n",
       "      <td>20439</td>\n",
       "      <td>-0.054365</td>\n",
       "      <td>0.426984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>508658626</td>\n",
       "      <td>2020-12-10 14:30:00</td>\n",
       "      <td>14</td>\n",
       "      <td>Twitter for Advertisers</td>\n",
       "      <td>Elsevier Energy</td>\n",
       "      <td>98</td>\n",
       "      <td>Elsevier and the EditorsinChief are pleased to...</td>\n",
       "      <td>ElsevierEnergy</td>\n",
       "      <td>Oxford, England</td>\n",
       "      <td>False</td>\n",
       "      <td>6615</td>\n",
       "      <td>508</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2607105006</td>\n",
       "      <td>2020-12-22 21:28:52</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Arwyn Thomas</td>\n",
       "      <td>1</td>\n",
       "      <td>From better climate change education to improv...</td>\n",
       "      <td>siwarr5</td>\n",
       "      <td>Carmarthen</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>133</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.345238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19609660</td>\n",
       "      <td>2020-12-22 21:24:10</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Tom Gillispie, EDITOR/WRITER</td>\n",
       "      <td>0</td>\n",
       "      <td>climate change Links to FIXING CLIMATE CHANGE ...</td>\n",
       "      <td>EDITORatWORK</td>\n",
       "      <td>Rural Hall, North Carolina, USA</td>\n",
       "      <td>False</td>\n",
       "      <td>4191</td>\n",
       "      <td>3708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19609660</td>\n",
       "      <td>2020-12-21 22:52:09</td>\n",
       "      <td>1</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Tom Gillispie, EDITOR/WRITER</td>\n",
       "      <td>1</td>\n",
       "      <td>climate change The 11TH HOUR FOR THE EARTH cli...</td>\n",
       "      <td>EDITORatWORK</td>\n",
       "      <td>Rural Hall, North Carolina, USA</td>\n",
       "      <td>False</td>\n",
       "      <td>4191</td>\n",
       "      <td>3708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                 date  retweets                   source  \\\n",
       "0  2184934963  2020-12-22 23:22:20        71          Twitter Web App   \n",
       "1   508658626  2020-12-10 14:30:00        14  Twitter for Advertisers   \n",
       "2  2607105006  2020-12-22 21:28:52         0          Twitter Web App   \n",
       "3    19609660  2020-12-22 21:24:10         0          Twitter Web App   \n",
       "4    19609660  2020-12-21 22:52:09         1          Twitter Web App   \n",
       "\n",
       "                         author  likes  \\\n",
       "0                      GO GREEN     91   \n",
       "1               Elsevier Energy     98   \n",
       "2                  Arwyn Thomas      1   \n",
       "3  Tom Gillispie, EDITOR/WRITER      0   \n",
       "4  Tom Gillispie, EDITOR/WRITER      1   \n",
       "\n",
       "                                                text    twitter_name  \\\n",
       "0  The death of summer Arctic ice our Earth coole...    ECOWARRIORSS   \n",
       "1  Elsevier and the EditorsinChief are pleased to...  ElsevierEnergy   \n",
       "2  From better climate change education to improv...         siwarr5   \n",
       "3  climate change Links to FIXING CLIMATE CHANGE ...    EDITORatWORK   \n",
       "4  climate change The 11TH HOUR FOR THE EARTH cli...    EDITORatWORK   \n",
       "\n",
       "                          location  verified  followers  friends  polarity  \\\n",
       "0                              NaN     False      23415    20439 -0.054365   \n",
       "1                  Oxford, England     False       6615      508  0.387500   \n",
       "2                       Carmarthen     False         22      133  0.261905   \n",
       "3  Rural Hall, North Carolina, USA     False       4191     3708  0.000000   \n",
       "4  Rural Hall, North Carolina, USA     False       4191     3708  0.000000   \n",
       "\n",
       "   subjectivity    label  \n",
       "0      0.426984        0  \n",
       "1      0.633333        1  \n",
       "2      0.345238        1  \n",
       "3      0.000000  neutral  \n",
       "4      0.000000  neutral  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding label based on polarity score\n",
    "conditions = [\n",
    "    (clim['polarity'] < 0),\n",
    "    (clim['polarity'] > 0),\n",
    "    (clim['polarity'] == 0)]\n",
    "\n",
    "values = [0,1, 'neutral']\n",
    "\n",
    "clim['label'] = np.select(conditions, values)\n",
    "\n",
    "clim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0136ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping neutral entries\n",
    "clim = clim.drop(clim[clim['label'] == 'neutral'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05eeea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping all columns except text and label\n",
    "clim = clim.drop(columns = ['id','date','source','author','twitter_name','location','verified','retweets','likes','followers','friends','polarity','subjectivity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bed581ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 270 entries, 0 to 395\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    270 non-null    object\n",
      " 1   label   270 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 6.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 270 entries, 0 to 395\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    270 non-null    string\n",
      " 1   label   270 non-null    int64 \n",
      "dtypes: int64(1), string(1)\n",
      "memory usage: 6.3 KB\n"
     ]
    }
   ],
   "source": [
    "clim.info()\n",
    "clim['text'] = clim['text'].astype('string')\n",
    "clim['label'] = clim['label'].astype('int64')\n",
    "clim.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69be93b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.head()\n",
    "bt = bt.drop(columns=['tweetid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb05b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.rename(columns={'sentiment': \"label\", 'message':'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8c4a760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43943 entries, 0 to 43942\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   43943 non-null  int64 \n",
      " 1   text    43943 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 686.7+ KB\n"
     ]
    }
   ],
   "source": [
    "bt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d681a025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    22962\n",
       " 2     9276\n",
       " 0     7715\n",
       "-1     3990\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt['label'].value_counts() # imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88dd5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = bt.drop(bt[bt['label'] ==  2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d0c82f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = bt.drop(bt[bt['label'] == 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcb886a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.dropna(subset=['label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bd5e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (bt['label'] == -1),\n",
    "    (bt['label'] == 1)]\n",
    "\n",
    "values = [0,1]\n",
    "\n",
    "bt['sent'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f662594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt['label'] = bt['sent']\n",
    "bt=bt.drop(columns=['sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91ce4841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26952 entries, 0 to 43942\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   26952 non-null  int32 \n",
      " 1   text    26952 non-null  string\n",
      "dtypes: int32(1), string(1)\n",
      "memory usage: 526.4 KB\n"
     ]
    }
   ],
   "source": [
    "bt['text'] = bt['text'].astype(\"string\")\n",
    "bt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fafe893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    22962\n",
       "0     3990\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed77a262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2117 entries, 0 to 2116\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    2117 non-null   object\n",
      " 1   label   2117 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 33.2+ KB\n"
     ]
    }
   ],
   "source": [
    "json.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ae73255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1585\n",
       "1     532\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b49f6630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29339 entries, 0 to 2116\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    29339 non-null  object\n",
      " 1   label   29339 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 687.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_list = [clim, bt, json]\n",
    "df = pd.concat(df_list)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1257a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ee963e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    23684\n",
       "0     5655\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c5801f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\sayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download the lexicon\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "# Import the lexicon\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create an instance of SentimentIntensityAnalyzer\n",
    "sent_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "faf132b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')  # Download the punkt tokenizer if not already downloaded\n",
    "\n",
    "df['tokens'] = df['text'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "893c5765",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"sustainability\", \"environmental\", \"conservation\", \"recycling\", \"sustainable\",\n",
    "                         \"responsibility\", \"green\", \"eco-friendly\", \"renewable\", \"carbon\", \"climate\", \"ecosystem\",\n",
    "                         \"planet\", \"biodiversity\", \"energy\", \"water\", \"pollution\", \"reduction\", \"renewability\",\n",
    "                         \"ecological\", \"renewable\", \"greenhouse\", \"clean\", \"solar\", \"wind\", \"earth\", \"sustainable\",\n",
    "                         \"planet\", \"ecology\", \"ocean\", \"forest\", \"organic\", \"earth-friendly\", \"bio\", \"ethics\",\n",
    "                         \"conservationist\", \"sustain\", \"renew\", \"ethical\", \"greenery\", \"saver\", \"sustainable\",\n",
    "                         \"conservator\", \"recycler\", \"biodegradable\", \"natural\", \"greenery\", \"environment\",\n",
    "                         \"saver\", \"earth-saving\", \"sustainability\", \"green-living\", \"clean\", \"responsible\",\n",
    "                         \"preservation\", \"regeneration\", \"ecosystem\", \"safeguarding\"]\n",
    "filtered_df = df[df['tokens'].apply(lambda tokens: any(keyword in tokens for keyword in keywords))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "923214ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19287\n",
       "0     2412\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb47febf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38574 entries, 20004 to 2115\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    38574 non-null  string\n",
      " 1   label   38574 non-null  int64 \n",
      " 2   tokens  38574 non-null  object\n",
      "dtypes: int64(1), object(1), string(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    19287\n",
       "1    19287\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "df1 = filtered_df.loc[filtered_df['label'] == 0]\n",
    "df2 = filtered_df.loc[filtered_df['label'] == 1]\n",
    "df1_sampled=resample(df1, replace=True,\n",
    "                     n_samples= 19287,\n",
    "                     random_state=42)\n",
    "# reproducible results\n",
    "filtered_df= pd.concat([df1_sampled, df2])\n",
    "filtered_df.info()\n",
    "filtered_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e99e7ea",
   "metadata": {
    "id": "7wu9VN_vq5K8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2a9314f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64QjTenEsEMZ",
    "outputId": "3162a368-8e1c-4f25-df33-121688bdcbfe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label', 'tokens'], dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9832c6c",
   "metadata": {
    "id": "BQPFsQmJshU9"
   },
   "source": [
    "Split it into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2663d42d",
   "metadata": {
    "id": "3xHatfzwuAHW"
   },
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "486d2c58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eK5zpOjKumhL",
    "outputId": "058f4535-834d-4c7c-d64e-bba08f648563"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33       We've ordered 25, and we expect to continue to...\n",
       "42753    RT @AC_screenwriter: Climate change is here an...\n",
       "39989    RT As The GOP Was Calling Obama A Weak Leader,...\n",
       "20181    RT @mslopatto: If you want actual accurate rep...\n",
       "4675     RT @SenSanders: We have a president-elect who ...\n",
       "                               ...                        \n",
       "17851    Trumps actions on climate change are an assaul...\n",
       "17875    RT @GreenStar_UK: There has always been reason...\n",
       "40680    Changing climate change starts with you. Sign ...\n",
       "41832    RT @TheFederalist1: New Great Lakes Study Blow...\n",
       "1618     And in government services, there is both supp...\n",
       "Name: text, Length: 22004, dtype: string"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15740020",
   "metadata": {
    "id": "sWIIsmUXsnxO"
   },
   "source": [
    "We will assign the max length of the sequence as the average length of all the tweets + 2 (arbitrary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63612366",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8HC4nywLEa2a",
    "outputId": "982c0b5a-dc87-4eec-b226-d62e8b0199ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH = math.ceil((X_train.apply(lambda x: len(str(x).split())).mean()))+2\n",
    "MAX_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf112eb",
   "metadata": {
    "id": "HBT9TCOEtDek"
   },
   "source": [
    "Let's initialize the tokenizer and add a PAD token ane and EOS (end of text) token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0df0a93b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130,
     "referenced_widgets": [
      "c9912049a982406d932e3adc9fe9d61c",
      "7d5b54e17c354b1f800f81d4a5428ff9",
      "21566811379146c8b55caf7b0a9c5b27",
      "ba51d2f688d84cf19773787a27583f4c",
      "e6bc18dd228142a3864176937738086a",
      "9bdd99caf0ad4f038e731883dce2146e",
      "bce97fa787184732a997abc82a931e05",
      "7dc0ed7811c846b2bf71e8b4e938a0ae",
      "4ba8ac9b9cc14acca878c21c0e7072d5",
      "e1f6d37f989543ce87e12a1f73446bba",
      "af94ed620f9546a191a5f61685e15cf5",
      "dab83b336aa246e8b0e9538eb0db0a34",
      "2395423f62884341b2abca5418552ecf",
      "5aef99c2bf354ed7bc518dd346eea6f8",
      "5221c7c45d0046b99285d0dff6a801b0",
      "32bd62bd982a42ad8910bfea5142b583",
      "6e9eb2f64a504f908d3e6928e4303353",
      "ea6fb84bd978400c89d313411bdd23db",
      "34b011e3fc354d7eb5073d3700ba917a",
      "62b30326d739469f80f3f403ae82b732",
      "dbc56bed04ce46b99494f2fa3ea6effc",
      "5a4c92e4b3b644d4a47ba20ae282c1ae",
      "a2a045421951430ebc57f44047ce87e4",
      "cbc03f6526d449069002c410565f94c7",
      "67c4e93657c543a2925448c30008fd02",
      "fae76282569d42db9be95f323b49d930",
      "306a492a3c8a47ea9bacd9910978bea9",
      "c3f2f32f23bb474f8aab66dcf318da0b",
      "6117904a079d438fbaf3ab4da16fe4a2",
      "76c2f214cc00486aad6cdefcdffcdaa0",
      "5125f72fff9e41cb9ecb0fc108e589c9",
      "6ffa8f079c6442cbb1f04c45fa61930f",
      "40f0381f1e41421db0950145689872a9"
     ]
    },
    "id": "b46ZXowVzT2O",
    "outputId": "b5557cb5-582a-48e5-fb03-5fc809c4a4ad"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458fa52f942d45deb5377ad40ed29d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayan\\Anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sayan\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a496bfe060ee4f1bbfbf88efccb2ddfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de71582cfe0439f90210bab1795bf80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d412cb2d949b4d0eb507b54b1b204a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e416fbf8f3584151bbeefd7353e62ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PAD_TOKEN = \"<|pad|>\"\n",
    "EOS_TOKEN = \"<|endoftext|>\"\n",
    "\n",
    "# this will download and initialize the pre trained tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\",\n",
    "    pad_token=PAD_TOKEN,\n",
    "    eos_token=EOS_TOKEN,\n",
    "    max_length=MAX_LENGTH,\n",
    "    is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba2ce68",
   "metadata": {
    "id": "xjme_839tWG-"
   },
   "source": [
    "We add the EOS token at the end of each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35ae66e3",
   "metadata": {
    "id": "Pqk2q61ZinYR"
   },
   "outputs": [],
   "source": [
    "X_train = [str(ex) + EOS_TOKEN for ex in X_train]\n",
    "X_test = [str(ex) + EOS_TOKEN for ex in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca8387d",
   "metadata": {
    "id": "LDHLDYV9tbKa"
   },
   "source": [
    "We pass the tweets through the tokenizer, padding them to the max_length. This is a list so we need to stack them to create a tensor input (using tf.convert_to_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "724d54b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NYQY3XZ0uU_o",
    "outputId": "60afae50-9787-4fc8-8e77-06ee81431217"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayan\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2619: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train_ = [tokenizer(str(x), return_tensors='tf', max_length=MAX_LENGTH, truncation=True, pad_to_max_length=True, add_special_tokens=True)['input_ids'] for x in X_train]\n",
    "X_test_ = [tokenizer(str(x), return_tensors='tf', max_length=MAX_LENGTH, truncation=True, pad_to_max_length=True, add_special_tokens=True)['input_ids'] for x in X_test]\n",
    "\n",
    "X_train_in = tf.squeeze(tf.convert_to_tensor(X_train_), axis=1)\n",
    "X_test_in = tf.squeeze(tf.convert_to_tensor(X_test_), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f720df99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gHyZbbcWuuGZ",
    "outputId": "68bc1351-96ae-4419-bc94-830c5dd4c94b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(22,), dtype=int32, numpy=\n",
       "array([ 1135,  1053,  6149,  1679,    11,   290,   356,  1607,   284,\n",
       "        2555,   284,  1325,  1111,   832, 12673,    11,   355,   880,\n",
       "         355,  4896,   287, 17173])>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_in[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8b0fdf",
   "metadata": {
    "id": "KpIVjp4Tt55r"
   },
   "source": [
    "We will also get the mask from the tokenizer (1 is token, 0 is pad token) the same we did for the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14219fa2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edYk0Rdk0IPA",
    "outputId": "5cf9af78-bf2f-4297-b845-5615ec51ee37"
   },
   "outputs": [],
   "source": [
    "X_train_mask_ = [tokenizer(str(x), return_tensors='tf', max_length=MAX_LENGTH, truncation=True, pad_to_max_length=True, add_special_tokens=True)[\"attention_mask\"] for x in X_train]\n",
    "X_test_mask_ = [tokenizer(str(x), return_tensors='tf', max_length=MAX_LENGTH, truncation=True, pad_to_max_length=True, add_special_tokens=True)[\"attention_mask\"] for x in X_test]\n",
    "\n",
    "X_train_mask = tf.squeeze(tf.convert_to_tensor(X_train_mask_), axis=1)\n",
    "X_test_mask = tf.squeeze(tf.convert_to_tensor(X_test_mask_), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58132c1",
   "metadata": {
    "id": "bOx8Nr1iuK0D"
   },
   "source": [
    "We are now ready to pass the inputs through the model.\n",
    "Next we need to initilize GPT2 for TF and set it in training mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f1c0c21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "8a8f6f15d8754a82aee41b58e9591d8c",
      "4d54e0ad3264452ba0a1eaa3f9cac29f",
      "c1f0bb443ba549b288b1d6e8de38792e",
      "991821ed1e0846c3b16b1a0306e57e8b",
      "d67785040cf84061aa58ae283decae08",
      "775e002a79d841e5814ebad36c28dc8e",
      "6ce31c1666224039bdf7f4c3398bfca3",
      "afd17d38768540079b15aee78e31f6ef",
      "6248b33ac90c48a486ec591b970f3ad4",
      "6721812efc8d497eb6e4805fd196f5eb",
      "411fe9038aec4b93bed67fb493a32618"
     ]
    },
    "id": "kD4ws3zm5Zc8",
    "outputId": "aca0a09b-51c8-43e2-d040-70d1806bf221"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1fab0966e5149eeaf4794f67dfe69bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2Model.\n",
      "\n",
      "All the weights of TFGPT2Model were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFGPT2Model.from_pretrained(\"gpt2\", use_cache=False,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id)\n",
    "model.training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9776162",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nKkgOJV05X94",
    "outputId": "f9f81133-53cb-4762-8136-58794d0338fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x196bbd80190>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf7b759",
   "metadata": {
    "id": "K7z-q10mvA0d"
   },
   "source": [
    "Set the GPT2 pre-trained layers as non trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5602a427",
   "metadata": {
    "id": "-O3PxYSNHyve"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f64e526c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Km2IJikE2sTm",
    "outputId": "35e18a47-8ad8-4e01-9e07-2809bd4b6938"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfgpt2_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer (TFGPT2MainLaye  multiple                 124440576 \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,440,576\n",
      "Trainable params: 0\n",
      "Non-trainable params: 124,440,576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea5098f",
   "metadata": {
    "id": "f_woWSvvvMdw"
   },
   "source": [
    "Next we build on top of GPT2.\n",
    "The model takes in tokens and mask tensors. The outputs are the last hidden states of the last layer in the transformer. These are reduced using the mean over the sequence length, passed through 2 dense layers with dopout in between. The output layer has three node (softmax activation function for probabilities) for the three classes we want to predict (Negative, Neutral and Positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8df1039c",
   "metadata": {
    "id": "-kzjWN8yvAHj"
   },
   "outputs": [],
   "source": [
    "input = tf.keras.layers.Input(shape=(None,), dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(None,), dtype='int32')\n",
    "x = model(input, attention_mask=mask)\n",
    "#x = x.last_hidden_state[:, -1]\n",
    "x = tf.reduce_mean(x.last_hidden_state, axis=1)\n",
    "x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "output = tf.keras.layers.Dense(3, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "409896be",
   "metadata": {
    "id": "XZqhNq5u2fI5"
   },
   "outputs": [],
   "source": [
    "clf = tf.keras.Model([input, mask], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0903f9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YrFOc6oeI-dG",
    "outputId": "e8ead82d-fe3d-4d78-aa65-72ed7cf55617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " tfgpt2_model (TFGPT2Model)     TFBaseModelOutputWi  124440576   ['input_1[0][0]',                \n",
      "                                thPastAndCrossAtten               'input_2[0][0]']                \n",
      "                                tions(last_hidden_s                                               \n",
      "                                tate=(None, None, 7                                               \n",
      "                                68),                                                              \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  (None, 768)         0           ['tfgpt2_model[0][0]']           \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 16)           12304       ['tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 16)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 3)            51          ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 124,452,931\n",
      "Trainable params: 12,355\n",
      "Non-trainable params: 124,440,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852e4e4f",
   "metadata": {
    "id": "FJqkOZqJyGT7"
   },
   "source": [
    "Next we compile the model choosing the learning rate, loss function and the metric to monitor. Also a callback function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "754fd935",
   "metadata": {
    "id": "X4KrjE58_Ela"
   },
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0005\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate)\n",
    "#loss=tf.keras.losses.BinaryCrossentropy()\n",
    "loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "clf.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0ac0a463",
   "metadata": {
    "id": "HD2ppmZVqwQf"
   },
   "outputs": [],
   "source": [
    "callbacks = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"accuracy\", verbose=1, patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56906215",
   "metadata": {
    "id": "GxEzyIoHyisD"
   },
   "source": [
    "Last thing we need to do is preparing the target tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b39be7a",
   "metadata": {
    "id": "ehe1Rjir3qlD"
   },
   "outputs": [],
   "source": [
    "#def map_sentiment(value):\n",
    " # if value == 'Negative':\n",
    "  #  return 0\n",
    "  #if value == 'Neutral':\n",
    "  #  return 1\n",
    "  #if value == 'Positive':\n",
    "  #  return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "311dbccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sentiment(value):\n",
    "  if value == 0:\n",
    "    return 0\n",
    "  else:\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "668e39c9",
   "metadata": {
    "id": "WMSKFwIu1E-1"
   },
   "outputs": [],
   "source": [
    "y_train_ = y_train.map(map_sentiment)\n",
    "y_test_ = y_test.map(map_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f1d32ea3",
   "metadata": {
    "id": "NI407MGy4QKA"
   },
   "outputs": [],
   "source": [
    "y_train_in = tf.constant(y_train_, dtype=tf.int32)\n",
    "y_test_in = tf.constant(y_test_, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f4baef60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ShQqGADWOcJe",
    "outputId": "cc0490c5-c566-4199-9ff9-50a2f28ba616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sayan\\AppData\\Local\\Temp/ipykernel_9936/2874510872.py:1: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.run_functions_eagerly` instead of the experimental version.\n"
     ]
    }
   ],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff2385f",
   "metadata": {
    "id": "ydGFl-GJytDf"
   },
   "source": [
    "We then train the model passing number of epochs, batch_size and validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b799c701",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zHHlvvpBoBU",
    "outputId": "bd85ba61-7d1f-499c-f9e6-7fb3c583db2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/551 [=======>......................] - ETA: 15:41 - loss: 1.9533 - accuracy: 0.6682"
     ]
    }
   ],
   "source": [
    "history = clf.fit([X_train_in, X_train_mask], y_train_in, epochs=30, batch_size=32, validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59d1ab2",
   "metadata": {
    "id": "oL_gByEIzIDO"
   },
   "source": [
    "We can now evaluate the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c136f34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_f16u8TB6t9",
    "outputId": "3ec64c4e-4e80-4573-e54f-eb6edb08e3c1"
   },
   "outputs": [],
   "source": [
    "clf.evaluate([X_test_in, X_test_mask], y_test_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c0f477",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nscIr_bltNY",
    "outputId": "e1102873-3e01-42f9-f424-d30c13d13378"
   },
   "outputs": [],
   "source": [
    "clf.training = False\n",
    "y_pred = clf.predict([X_test_in, X_test_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ea8466",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OT4Av95jmpUt",
    "outputId": "917d0a6f-0883-4b0c-cc16-01a33f836c4a"
   },
   "outputs": [],
   "source": [
    "y_pred_out = tf.math.argmax(y_pred, axis=-1)\n",
    "y_pred_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847e28f9",
   "metadata": {
    "id": "CJiVWYjBz-fF"
   },
   "source": [
    "We can now evaluate the model on the test set using the classification report and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a818f",
   "metadata": {
    "id": "RBe9C66i2KSi"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1caf87",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LBHhKseWiMFg",
    "outputId": "f2b27ce8-1f85-4036-abc0-9b5d49b5cc5f"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test_in, y_pred_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3ba36f",
   "metadata": {
    "id": "0K1-fYGc1wXP"
   },
   "source": [
    "We notice right away that the model, overall, has a good precision and recall on all classes. The model has more difficulties in predicting the negative class (0), expecially recall.\n",
    "\n",
    "Of all the predicted negative, 60% were actually negative - the model has a decent precision. Of all the ones that were actually negative, only 56% were predicted negative - the model struggles recalling (recall metric) the negative class.\n",
    "\n",
    "Below is the confusion matrix that helps understand it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2136fe33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "at565HvhlV5w",
    "outputId": "d8d958db-7364-4d5b-d1da-f753bfd04885"
   },
   "outputs": [],
   "source": [
    "confusion_df = pd.DataFrame(confusion_matrix(y_test_in, y_pred_out))\n",
    "confusion_df.index = ['Actual 0', 'Actual 1']\n",
    "confusion_df.columns = ['Predicted 0', 'Predicted 1']\n",
    "confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee74226c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "FDZUeFX8lW_n",
    "outputId": "f2ac829a-f6f0-435d-9b37-e87ba7807021"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(confusion_df, annot=True, fmt='d', linewidths=0.5) \n",
    "plt.yticks(rotation=0)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4ba96b",
   "metadata": {
    "id": "y3Ekf7G12UmA"
   },
   "source": [
    "Overall the model doesn't seem to outperform logistic regression and random forest. \n",
    "It's worth noticing that the model is overfitting so it would be nice to re-train it, playing with learning rate, weight decay and dropout rate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45df8ac6",
   "metadata": {
    "id": "bDS7Na_en4lY"
   },
   "outputs": [],
   "source": [
    "#clf.save_weights('/content/gdrive/My Drive/Data Science/saved_model/GPT2_transfer_learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2edf57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
